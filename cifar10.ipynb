{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoFMdZ7iLJqg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets.utils import download_url\n",
        "dataset_url=\"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url,'.')\n",
        "with tarfile.open('./cifar10.tgz','r:gz') as tar:\n",
        "  tar.extractall(path='./data')\n",
        "\n",
        "data_dir='./data/cifar10'\n",
        "print(os.listdir(data_dir))\n",
        "classes=os.listdir(data_dir+'/train')\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "ASbOhYMduAf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats= ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "train_tfm=tt.Compose([tt.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
        "                      tt.RandomHorizontalFlip(),\n",
        "                      tt.ToTensor(),\n",
        "                      tt.Normalize(*stats,inplace=True)])\n",
        "valid_tfm=tt.Compose([tt.ToTensor(),tt.Normalize(*stats)])"
      ],
      "metadata": {
        "id": "Xwq-awRFt_5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Skjf5NcgwtS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=ImageFolder(data_dir+'/train',train_tfm)\n",
        "val_ds=ImageFolder(data_dir+'/test',valid_tfm)"
      ],
      "metadata": {
        "id": "o2yf6mcHt-x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=400\n",
        "train_dl=DataLoader(train_ds,batch_size,shuffle=True,num_workers=2,pin_memory=True)\n",
        "val_dl=DataLoader(val_ds,batch_size*2,num_workers=2,pin_memory=True)"
      ],
      "metadata": {
        "id": "AitTOqhkw0sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(images,means,stds):\n",
        "  means=torch.tensor(means).reshape(1,3,1,1)\n",
        "  stds=torch.tensor(stds).reshape(1,3,1,1)\n",
        "  return images*stds+means\n",
        "def show_batch(dl):\n",
        "  for images,labels in dl:\n",
        "    fig,ax=plt.subplots(figsize=(12,12))\n",
        "    ax.set_xticks([]);ax.set_yticks([])\n",
        "    denorm_images=denormalize(images,*stats)\n",
        "    ax.imshow(make_grid(denorm_images[:64],nrow=8).permute(1,2,0).clamp(0,1))\n",
        "    break"
      ],
      "metadata": {
        "id": "Qo8zw0sfxV-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(train_dl)"
      ],
      "metadata": {
        "id": "wkjINkuiyfZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "EymG_H4azAR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "ZfR6MkDszIkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl=DeviceDataLoader(train_dl,device)\n",
        "val_dl=DeviceDataLoader(val_dl,device)"
      ],
      "metadata": {
        "id": "FZfWDya5zPs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SRB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(3,3,3,1,1)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.conv2=nn.Conv2d(3,3,3,1,1)\n",
        "    self.relu2=nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out=self.conv1(x)\n",
        "    out=self.relu1(out)\n",
        "    out=self.conv2(out)\n",
        "    return self.relu2(out)+x"
      ],
      "metadata": {
        "id": "yJ5MjmUmzidD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_r=to_device(SRB(),device)\n",
        "for img,label in train_dl:\n",
        "  out=s_r(img)\n",
        "  print(out.shape)\n",
        "  break\n",
        "del s_r,img,label\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Lkf2v_JI0on1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs,label):\n",
        "  _,preds=torch.max(outputs,dim=1)\n",
        "  return torch.tensor(torch.sum(preds==label).item()/len(preds))\n",
        "class ImageClassificationBase(nn.Module):\n",
        "  def training_step(self,batch):\n",
        "    img,label=batch\n",
        "    out=self(img)\n",
        "    loss=F.cross_entropy(out,label)\n",
        "    return loss\n",
        "  def validation_step(self,batch):\n",
        "    img,label=batch\n",
        "    out=self(img)\n",
        "    loss=F.cross_entropy(out,label)\n",
        "    acc=accuracy(out,label)\n",
        "    return {'val_loss':loss.detach(),'val_acc':acc}\n",
        "  def validation_epoch_end(self,outputs):\n",
        "    batch_losses=[x['val_loss'] for x in outputs]\n",
        "    epoch_loss=torch.stack(batch_losses).mean()\n",
        "    batch_accs=[x['val_acc'] for x in outputs]\n",
        "    epoch_acc=torch.stack(batch_accs).mean()\n",
        "    return {'val_loss':epoch_loss.item(),'val_acc':epoch_acc.item()}\n",
        "  def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "IT1zr8BN1UIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels,out_channels,pool=False):\n",
        "  layers=[nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1),\n",
        "          nn.BatchNorm2d(out_channels),\n",
        "          nn.ReLU(inplace=True)]\n",
        "  if pool:layers.append(nn.MaxPool2d(2))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "  def __init__(self,in_channels,num_classes):\n",
        "    super().__init__()#(3,32,32)\n",
        "    self.conv1=conv_block(in_channels,64)#(64,32,32)\n",
        "    self.conv2=conv_block(64,128,pool=True)#(128,16,16)\n",
        "    self.res1=nn.Sequential(conv_block(128,128),conv_block(128,128))\n",
        "    self.conv3=conv_block(128,256,pool=True)\n",
        "    self.conv4=conv_block(256,512)\n",
        "    self.res2=nn.Sequential(conv_block(512,512),conv_block(512,512))\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.classifier=nn.Sequential(nn.Flatten(),\n",
        "                                  nn.Dropout(0.2),\n",
        "                                  nn.Linear(512,num_classes))\n",
        "  def forward(self,xb):\n",
        "    out=self.conv1(xb)\n",
        "    out=self.conv2(out)\n",
        "    out=self.res1(out)+out\n",
        "    out=self.conv3(out)\n",
        "    out=self.conv4(out)\n",
        "    out=self.res2(out)+out\n",
        "    out=self.avgpool(out)\n",
        "    out=self.classifier(out)\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "7kmPqLrN4RK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=to_device(ResNet9(3,10),device)\n",
        "model"
      ],
      "metadata": {
        "id": "9fiCRpes7s0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  outputs=[model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    return param_group['lr']\n",
        "def fit_one_cycle(epochs,max_lr,model,train_loader,val_loader,weight_decay=0,grad_clip=None,opt_func=torch.optim.SGD):\n",
        "  torch.cuda.empty_cache()\n",
        "  history=[]\n",
        "  optimizer=opt_func(model.parameters(),max_lr,weight_decay=weight_decay)\n",
        "  sched=torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,epochs=epochs,steps_per_epoch=len(train_loader))\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_losses=[]\n",
        "    lrs=[]\n",
        "    for batch in train_loader:\n",
        "      loss=model.training_step(batch)\n",
        "      train_losses.append(loss)\n",
        "      loss.backward()\n",
        "      if grad_clip:\n",
        "        nn.utils.clip_grad_value_(model.parameters(),grad_clip)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      lrs.append(get_lr(optimizer))\n",
        "      sched.step()\n",
        "    result=evaluate(model,val_loader)\n",
        "    result['train_loss']=torch.stack(train_losses).mean().item()\n",
        "    result['lrs']=lrs\n",
        "    model.epoch_end(epoch,result)\n",
        "    history.append(result)\n",
        "  return history"
      ],
      "metadata": {
        "id": "fjXgahUuADp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img,l in val_dl:\n",
        "  print(img.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "MxoGl3rYFDUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=[evaluate(model,val_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "Xej83P1uDOAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=8\n",
        "max_lr=0.01\n",
        "grad_clip=0.1\n",
        "weight_decay=1e-4\n",
        "opt_func=torch.optim.Adam"
      ],
      "metadata": {
        "id": "03hSAQAGKzz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n",
        "                             grad_clip=grad_clip,\n",
        "                             weight_decay=weight_decay,\n",
        "                             opt_func=opt_func)"
      ],
      "metadata": {
        "id": "wZBQ9WuvKzUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time='5:10'"
      ],
      "metadata": {
        "id": "5DOi4rWgKyo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_img(img,model):\n",
        "  xb=to_device(img.unsqueeze(0),device)\n",
        "  yb=model(xb)\n",
        "  _,preds=torch.max(yb,dim=1)\n",
        "  return train_ds.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "cAtjjAQZOl5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,label=val_ds[123]\n",
        "plt.imshow(img.permute(1,2,0).clamp(0,1))\n",
        "train_ds.classes[label],pred_img(img,model)"
      ],
      "metadata": {
        "id": "pXJnKYGUPDl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'cifar10-resnet9.pth')"
      ],
      "metadata": {
        "id": "NU1QLkZIPpo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pxkPY8ZyP1xb"
      }
    }
  ]
}